# Awesome-Video-Reasoning [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

This is a repository for organizing papres related to Video Reasoning in Multimodal Large Language Models.

With the development of the video capabilities and reasoning capabilities of multimodal large language models, researchers have high hopes for the video reasoning capabilities of MLLM/LVLM.

#### :star: If you find this list useful, welcome to star it!

## Paper List (Updating...)

### Method

(7 May 2024) Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition. [arxiv](https://arxiv.org/abs/2501.03230) [code](https://github.com/scofield7419/Video-of-Thought)

### Bench/Dataset

(18 Dec 2024) Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces. [arxiv](https://arxiv.org/abs/2412.14171)

(22 Nov 2024) VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection. [arxiv](https://arxiv.org/abs/2411.14794v1) [code](https://github.com/hshjerry/VideoEspresso)

(23 May 2023) Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought. [arxiv](https://arxiv.org/abs/2305.13903)

### Multimodal Reasoning

(13 Feb 2025) MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency [arxiv](https://arxiv.org/abs/2502.09621)

(23 Jan 2025) Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step [arxiv](https://arxiv.org/abs/2501.13926)

(13 Jan 2025) Imagine while Reasoning in Space: Multimodal Visualization-of-Thought [arxiv](https://arxiv.org/abs/2501.07542)

(9 Jan 2025) Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark [arxiv](https://www.arxiv.org/abs/2501.05444)

(30 Dec 2024) Slow Perception: Let's Perceive Geometric Figures Step-by-step [arxiv](https://arxiv.org/abs/2412.20631)

(29 Nov 2024) Interleaved-Modal Chain-of-Thought [arxiv](https://arxiv.org/abs/2411.19488)

(15 Nov 2024) Thinking Before Looking: Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination [arxiv](https://arxiv.org/abs/2411.12591)

(30 Oct 2024) Vision-Language Models Can Self-Improve Reasoning via Reflection [arxiv](https://arxiv.org/abs/2411.00855)

(23 Oct 2024) R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models [arxiv](https://arxiv.org/abs/2410.17885)

(21 Oct 2024) Improve Vision Language Model Chain-of-thought Reasoning [arxiv](https://arxiv.org/abs/2410.16198)

(11 Oct 2024) M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought [arxiv](https://arxiv.org/abs/2410.09220)

(6 Oct 2024) MC-CoT: A Modular Collaborative CoT Framework for Zero-shot Medical-VQA with LLM and MLLM Integration [arxiv](https://arxiv.org/abs/2410.04521)

(29 Sep 2024) CoT-ST: Enhancing LLM-based Speech Translation with Multimodal Chain-of-Thought [arxiv](https://arxiv.org/abs/2409.19510)

(7 Jul 2024) VideoCoT: A Video Chain-of-Thought Dataset with Active Annotation Tool [arxiv](https://arxiv.org/abs/2407.05355)

(13 Jun 2024) Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models [arxiv](https://arxiv.org/abs/2406.09403)

