# Awesome-Video-Reasoning [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

This is a repository for organizing papres related to Video Reasoning in Multimodal Large Language Models.

With the development of the video capabilities and reasoning capabilities of multimodal large language models, researchers have high hopes for the video reasoning capabilities of MLLM/LVLM.

#### :star: If you find this list useful, welcome to star it!

## Paper List (Updating...)

### Method

(7 May 2024) Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition. [arxiv](https://arxiv.org/abs/2501.03230) [code](https://github.com/scofield7419/Video-of-Thought)

### Bench/Dataset

(18 Dec 2024) Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces. [arxiv](https://arxiv.org/abs/2412.14171)

(22 Nov 2024) VideoEspresso: A Large-Scale Chain-of-Thought Dataset for Fine-Grained Video Reasoning via Core Frame Selection. [arxiv](https://arxiv.org/abs/2411.14794v1) [code](https://github.com/hshjerry/VideoEspresso)

(23 May 2023) Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought. [arxiv](https://arxiv.org/abs/2305.13903)
